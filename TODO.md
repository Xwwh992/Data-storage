- GNN 时序预测
- Transformer编码器解码器工作步骤
- BERT MLM NSP
- GPT LLAMA CHATGLM 在结构、激活函数、位置编码、训练任务的区别
- 预训练微调  LoRA原理和应用
- 数据量过大模型怎么加载
- GNN和LLM有什么结合方式
- 图神经网络用什么NORM  NORM细则
- hugging face    pert
- Teaching force  Beam search
- loss为nan  loss降不下来  并行训练  dropout
- transformer复杂度最高模块    Baseline
- KV Cache
- 长度外推  RAG  中文拼写纠错
- 大模型幻觉  prompt tuning  ICL
- Batch Norm Layer Norm
- MQA GQA RMSNorm SwiGLU
- ROC AUC
- 怎么解决数据不均衡
- long context
- Flash-attention 量化原理
- 数据结构 栈 队列 进程线程 OSI 物理层 数据链路层 TCP UDP
- IPSec
- 准确率 精确率 召回率计算 交叉熵损失 PPL